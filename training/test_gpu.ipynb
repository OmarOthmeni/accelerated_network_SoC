{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1641f9a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1+cu121\n",
      "is CUDA available ? True\n",
      "Card name : NVIDIA GeForce GTX 1650 with Max-Q Design\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"is CUDA available ? {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Card name : {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c073419f",
   "metadata": {},
   "source": [
    "After installing Pytorch, we run a small verification to see if we have the right version of cuda and the one that uses GPU to train faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1eb7db4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MarsCNN(\n",
      "  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (fc1): Linear(in_features=8192, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=24, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MarsCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MarsCNN, self).__init__()\n",
    "        # 1 input channel (gray), 16 output channels, 3x3 kernel\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # 16 input channels, 32 output channels, 3x3 kernel\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        \n",
    "        # After two 2x2 pools, 64x64 becomes 16x16\n",
    "        # 32 channels * 16 * 16 = 8192 features\n",
    "        self.fc1 = nn.Linear(32 * 16 * 16, 128)\n",
    "        self.fc2 = nn.Linear(128, 24) # 24 Output classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 32 * 16 * 16) # Flatten the images\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model and move to GPU\n",
    "model = MarsCNN().to('cuda') \n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0da777fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data_prepare.ipynb', 'test', 'train', 'validation']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir(r\"C:\\Users\\msi\\Desktop\\TECH_UP\\accelerated_network_SoC\\data\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e26cdcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4673 images for training.\n",
      "Found 990 images for validation.\n",
      "Found 1028 images for testing.\n",
      "Class mapping: {'apxs': 0, 'apxs cal target': 1, 'chemcam cal target': 2, 'chemin inlet open': 3, 'drill': 4, 'drill holes': 5, 'drt front': 6, 'drt side': 7, 'ground': 8, 'horizon': 9, 'inlet': 10, 'mahli': 11, 'mahli cal target': 12, 'mastcam': 13, 'mastcam cal target': 14, 'observation tray': 15, 'portion box': 16, 'portion tube': 17, 'portion tube opening': 18, 'rems uv sensor': 19, 'rover rear deck': 20, 'scoop': 21, 'turret': 22, 'wheel': 23}\n",
      "âœ… Mapping Synced: 24 classes identified.\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.ToTensor(), # Just 0.0 to 1.0, no normalization\n",
    "])\n",
    "class_names = sorted(os.listdir(r\"C:\\Users\\msi\\Desktop\\TECH_UP\\accelerated_network_SoC\\data\\train\"))\n",
    "class_to_idx = {name: i for i, name in enumerate(class_names)}\n",
    "\n",
    "# Datasets\n",
    "train_dataset = datasets.ImageFolder(\n",
    "    root=r\"C:\\Users\\msi\\Desktop\\TECH_UP\\accelerated_network_SoC\\data\\train\",\n",
    "    transform=transform\n",
    ")\n",
    "master_mapping = train_dataset.class_to_idx\n",
    "val_dataset = datasets.ImageFolder(\n",
    "    root=r\"C:\\Users\\msi\\Desktop\\TECH_UP\\accelerated_network_SoC\\data\\validation\",\n",
    "    transform=transform\n",
    ")\n",
    "val_dataset.class_to_idx = class_to_idx\n",
    "test_dataset = datasets.ImageFolder(\n",
    "    root=r\"C:\\Users\\msi\\Desktop\\TECH_UP\\accelerated_network_SoC\\data\\test\",\n",
    "    transform=transform\n",
    ")\n",
    "test_dataset.class_to_idx = class_to_idx\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "print(f\"Found {len(train_dataset)} images for training.\")\n",
    "print(f\"Found {len(val_dataset)} images for validation.\")\n",
    "print(f\"Found {len(test_dataset)} images for testing.\")\n",
    "print(f\"Class mapping: {train_dataset.class_to_idx}\")\n",
    "\n",
    "print(f\"âœ… Mapping Synced: {len(master_mapping)} classes identified.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7fcf088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model will output 24 classes\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "# 1. Setup Device (using your GTX 1650)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Check exactly what the model sees\n",
    "train_dataset = datasets.ImageFolder(root=r\"C:\\Users\\msi\\Desktop\\TECH_UP\\accelerated_network_SoC\\data\\train\",transform=transform)\n",
    "num_classes = len(train_dataset.classes)\n",
    "print(f\"Model will output {num_classes} classes\")\n",
    "\n",
    "# Update your model initialization\n",
    "model = MarsCNN()\n",
    "model.fc2 = nn.Linear(128, num_classes) # Forces match with folders\n",
    "model = model.to(device)\n",
    "\n",
    "# 4. Loss Function and Optimizer\n",
    "# CrossEntropyLoss is ideal for multi-class Martian terrain.\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001) # Adam is fast on GPUs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d873e2a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted IDs: [23 21  8  8 22 23 23 22 23 23 23 22  8  8  8 21 21 21 21 22  8  8  3  5\n",
      "  3 23  5 23  3  3  3 23]\n",
      "Actual IDs:    [0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "Epoch [1/10] | Loss: 1.6523 | Val Accuracy: 72.22%\n",
      "Predicted IDs: [ 0  0 13 14  0  0  0  0  0  0  0  0  1 14  1 21 10 21 21 22  3  3  3  3\n",
      "  3  3  3  3  3  9  3  3]\n",
      "Actual IDs:    [0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "Epoch [2/10] | Loss: 0.7807 | Val Accuracy: 67.78%\n",
      "Predicted IDs: [ 0  0 21 22  0  0  0  0  0  0  0  0  1  1  1 21 21 21  3  0  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3]\n",
      "Actual IDs:    [0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "Epoch [3/10] | Loss: 0.5201 | Val Accuracy: 88.69%\n",
      "Predicted IDs: [ 0  0 21 22  0  0  0  0 23  0  0  0  1  1  1 16 21 21  3 22  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3]\n",
      "Actual IDs:    [0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "Epoch [4/10] | Loss: 0.3218 | Val Accuracy: 89.09%\n",
      "Predicted IDs: [ 0  0 21 21  0  0  0  0  8  0  0  0  1  1  1 21 21 21 11  2  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3]\n",
      "Actual IDs:    [0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "Epoch [5/10] | Loss: 0.2405 | Val Accuracy: 92.02%\n",
      "Predicted IDs: [ 0  0 21 17  0  0  0  0 16  0  0  0  1  1  1 17 21 21 11  2  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3]\n",
      "Actual IDs:    [0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "Epoch [6/10] | Loss: 0.2029 | Val Accuracy: 92.12%\n",
      "Predicted IDs: [ 0  0  8  0  0  0  0  0 23  0  0  0  1  1  1 21 21 21 11  0  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3]\n",
      "Actual IDs:    [0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "Epoch [7/10] | Loss: 0.1676 | Val Accuracy: 94.65%\n",
      "Predicted IDs: [ 0  0 21  0  0  0  0  0  0  0  0  0  1  1  1 21 21 21 11  2  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3]\n",
      "Actual IDs:    [0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "Epoch [8/10] | Loss: 0.1226 | Val Accuracy: 94.95%\n",
      "Predicted IDs: [ 0  0  0  0  0  0  0  0  0  0  0  0  1  1  1 21 21 21  3  2  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3]\n",
      "Actual IDs:    [0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "Epoch [9/10] | Loss: 0.0960 | Val Accuracy: 95.45%\n",
      "Predicted IDs: [ 0  0 21  0  0  0  0  0  0  0  0  0  1  1  1  2 21 20  3  2  3  3  3  3\n",
      "  3  3  3  3  3  3  3  3]\n",
      "Actual IDs:    [0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "Epoch [10/10] | Loss: 0.0881 | Val Accuracy: 95.35%\n",
      "ðŸŽ‰ Training Complete!\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train() # Set to training mode\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad() # Reset the gradients\n",
    "        \n",
    "        # Forward Pass: Predict\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward Pass: Learn\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    # --- Validation Phase ---\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad(): # No need to calculate gradients for checking\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        images, labels = next(iter(val_loader))\n",
    "        outputs = model(images.to(device))\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        print(f\"Predicted IDs: {predicted.cpu().numpy()}\")\n",
    "        print(f\"Actual IDs:    {labels.numpy()}\")\n",
    "            \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] | Loss: {running_loss/len(train_loader):.4f} | Val Accuracy: {100 * correct / total:.2f}%\")\n",
    "\n",
    "print(\"ðŸŽ‰ Training Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "471abd62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model saved to mars_model_94acc.pth\n"
     ]
    }
   ],
   "source": [
    "# Define your save path\n",
    "MODEL_PATH = \"mars_model_94acc.pth\"\n",
    "\n",
    "# Save the model\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'num_classes': 24,\n",
    "    'accuracy': 94.0\n",
    "}, MODEL_PATH)\n",
    "\n",
    "print(f\"âœ… Model saved to {MODEL_PATH}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "accelerated-network-soc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
